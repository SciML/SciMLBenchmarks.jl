# Setup chunk for Weave: must be first in file
```julia; setup=true
using Pkg; Pkg.instantiate()
using Optimization
using OptimizationNLPModels
using CUTEst
using OptimizationOptimJL
using Ipopt
using OptimizationMOI
using OptimizationMOI: MOI as MOI
# Analysis and plotting
using DataFrames
using Plots
using StatsPlots
using StatsBase: countmap
```
---
title: CUTEst Unbounded Constrained Nonlinear Optimization Benchmarks
author: Alonso M. Cisneros
---

# Introduction

CUTEst, the Constraind and Unconstrained Testing Environment is, as the name suggests is a
collection of around 1500 problems for general nonlinear optimization used to test
optimization routines. The wrapper
[CUTEst.jl](https://github.com/JuliaSmoothOptimizers/CUTEst.jl) provides convenient access
to the problem collection, which we can leverage to test the optimizers made available by
Optimization.jl.


```julia
using Optimization
using OptimizationNLPModels
using CUTEst
using OptimizationOptimJL
using Ipopt
using OptimizationMOI
using OptimizationMOI: MOI as MOI
# Analysis and plotting
using DataFrames
using Plots
using StatsPlots
using StatsBase: countmap
```

# Benchmarks

We will be testing the [Ipopt]() and the [LBFGS]() optimizers on these classes of
problems.

```julia
# Standard low-memory optimizer set
optimizers = [
    ("GradientDescent", Optimization.GradientDescent()),
    ("LBFGS", Optimization.LBFGS()),
    ("ConjugateGradient", Optimization.ConjugateGradient()),
    ("NelderMead", Optimization.NelderMead()),
    ("SimulatedAnnealing", Optimization.SimulatedAnnealing()),
    ("ParticleSwarm", Optimization.ParticleSwarm()),
]

function get_stats(sol, optimizer_name)
    if hasfield(typeof(sol), :stats) && hasfield(typeof(sol.stats), :time)
        solve_time = sol.stats.time
    else
        solve_time = NaN
    end
    return (length(sol.u), solve_time, optimizer_name, Symbol(sol.retcode))
end

function run_benchmarks(problems, optimizers; chunk_size=3)
    problem = String[]
    n_vars = Int64[]
    secs = Float64[]
    solver = String[]
    retcode = Symbol[]

    optz = length(optimizers)
    n = length(problems)

    @info "Processing $(n) problems with $(optz) optimizers in chunks of $(chunk_size)"

    broadcast(c -> sizehint!(c, optz * n), [problem, n_vars, secs, solver, retcode])

    # Process problems in chunks to manage memory
    for chunk_start in 1:chunk_size:n
        chunk_end = min(chunk_start + chunk_size - 1, n)
        chunk_problems = problems[chunk_start:chunk_end]
        
        @info "Processing chunk $(div(chunk_start-1, chunk_size)+1)/$(div(n-1, chunk_size)+1): problems $(chunk_start)-$(chunk_end)"
        
        for (idx, prob_name) in enumerate(chunk_problems)
            current_problem = chunk_start + idx - 1
            @info "Problem $(current_problem)/$(n): $(prob_name)"
            
            nlp_prob = nothing
            try
                nlp_prob = CUTEstModel(prob_name)
                
                # Skip extremely large problems to prevent memory issues
                if nlp_prob.meta.nvar > 10000
                    @info "  Skipping $(prob_name) (too large: $(nlp_prob.meta.nvar) variables)"
                    finalize(nlp_prob)
                    continue
                end
                
                prob = OptimizationNLPModels.OptimizationProblem(nlp_prob, Optimization.AutoForwardDiff())
                
                for (optimizer_name, optimizer) in optimizers
                    try
                        sol = solve(prob, optimizer; maxiters = 1000, maxtime = 30.0)
                        @info "✓ Solved $(prob_name) with $(optimizer_name) - Status: $(sol.retcode)"
                        vars, time, alg, code = get_stats(sol, optimizer_name)
                        push!(problem, prob_name)
                        push!(n_vars, vars)
                        push!(secs, time)
                        push!(solver, alg)
                        push!(retcode, code)
                    catch e
                        @warn "✗ Failed to solve $(prob_name) with $(optimizer_name): $(e)"
                        push!(problem, prob_name)
                        push!(n_vars, -1)
                        push!(secs, NaN)
                        push!(solver, optimizer_name)
                        push!(retcode, :FAILED)
                    end
                end
                
            catch e
                @warn "✗ Failed to load problem $(prob_name): $(e)"
                # Add failure entries for all optimizers
                for (optimizer_name, optimizer) in optimizers
                    push!(problem, prob_name)
                    push!(n_vars, -1)
                    push!(secs, NaN)
                    push!(solver, optimizer_name)
                    push!(retcode, :LOAD_FAILED)
                end
            finally
                # Clean up resources
                if nlp_prob !== nothing
                    try
                        finalize(nlp_prob)
                    catch e
                        @warn "Failed to finalize $(prob_name): $(e)"
                    end
                end
            end
        end
        
        # Force garbage collection after each chunk
        GC.gc()
        @info "Completed chunk, memory usage cleaned up"
    end

    return DataFrame(problem = problem, n_vars = n_vars, secs = secs, solver = solver,
        retcode = retcode)
end
```

## Equality/Inequality constrained problems with unbounded variables

These problems have a constraint function that's subject to either equality or inequality
constraints, but the variables themselves are free. CUTEst contains 285 problems with
equality constraints and 114 with inequality constraints for a total of 299.

We start by analyzing the equality-constrained problems, of which there are 285. The
following figure shows the time to solution as a function of number of variables by
optimizer.

```julia
eq_unb_problems = CUTEst.select_sif_problems(min_con=1, only_equ_con=true, only_free_var=true)
@info "Testing $(length(eq_unb_problems)) equality-constrained unbounded problems"

# Analysis
eq_unb_results =  run_benchmarks(eq_unb_problems, optimizers)

# Calculate and display success rates for equality constrained
successful_codes = [:Success, :MaxIters, :MaxTime, :FirstOrderOptimal]
successful_results = filter(row -> row.retcode in successful_codes, eq_unb_results)
total_attempts = nrow(eq_unb_results)
successful_attempts = nrow(successful_results)
success_rate = total_attempts > 0 ? round(successful_attempts / total_attempts * 100, digits=1) : 0

@info "EQUALITY CONSTRAINED SUCCESS RATE: $(success_rate)% ($(successful_attempts)/$(total_attempts))"

@df eq_unb_results scatter(:n_vars, :secs,
        group = :solver,
        xlabel = "n. variables",
        ylabel = "secs.",
        title = "Time to solution by optimizer and number of vars",
    )
```

Next, we examine the same relationship for problems with inequality-constrained problems.

```julia
neq_unb_problems = CUTEst.select_sif_problems(min_con=1, only_ineq_con=true, only_free_var=true)
@info "Testing $(length(neq_unb_problems)) inequality-constrained unbounded problems"

# Analysis
neq_unb_results =  run_benchmarks(neq_unb_problems, optimizers)

# Calculate and display success rates for inequality constrained
successful_codes = [:Success, :MaxIters, :MaxTime, :FirstOrderOptimal]
successful_results = filter(row -> row.retcode in successful_codes, neq_unb_results)
total_attempts = nrow(neq_unb_results)
successful_attempts = nrow(successful_results)
success_rate = total_attempts > 0 ? round(successful_attempts / total_attempts * 100, digits=1) : 0

@info "INEQUALITY CONSTRAINED SUCCESS RATE: $(success_rate)% ($(successful_attempts)/$(total_attempts))"

@df neq_unb_results scatter(:n_vars, :secs,
        group = :solver,
        xlabel = "n. variables",
        ylabel = "secs.",
        title = "Time to solution by optimizer and number of vars",
    )
```

```julia, echo = false
try
    using SciMLBenchmarks
    folder = haskey(WEAVE_ARGS, :folder) ? WEAVE_ARGS[:folder] : ""
    file = haskey(WEAVE_ARGS, :file) ? WEAVE_ARGS[:file] : ""
    SciMLBenchmarks.bench_footer(folder, file)
catch e
    @warn "bench_footer failed: $e"
end
```