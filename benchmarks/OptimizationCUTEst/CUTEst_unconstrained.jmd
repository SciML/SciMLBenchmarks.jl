---
title: CUTEst Unconstrained Nonlinear Optimization Benchmarks
author: Alonso M. Cisneros
---

# Introduction

CUTEst, the Constrained and Unconstrained Testing Environment, is a collection of around 1500 problems for general nonlinear optimization used to test optimization routines. The wrapper [CUTEst.jl](https://github.com/JuliaSmoothOptimizers/CUTEst.jl) provides convenient access to the problem collection, which we can leverage to test the optimizers made available by Optimization.jl.


## Unconstrained problems

CUTEst contains 286 unconstrained problems. We will compare how the optimizers behave in
terms of the time to solution with respect to the number of variables.

total_attempts = nrow(unc_results)
successful_attempts = nrow(successful_results)
success_rate = total_attempts > 0 ? round(successful_attempts / total_attempts * 100, digits=1) : 0

println("SUCCESS RATE ANALYSIS:")
println("Total attempts: ", total_attempts)
println("Successful attempts: ", successful_attempts)
println("Success rate: ", success_rate, "%")

# Show distribution of return codes
println("Return code distribution:")
if total_attempts > 0
    for (code, count) in sort(collect(pairs(countmap(unc_results.retcode))), by=x->x[2], rev=true)
        println("  ", code, ": ", count, " occurrences")
    end
else
    println("  No results to analyze")
end

@df unc_results scatter(:n_vars, :secs,
        group = :solver,
        xlabel = "n. variables",
        ylabel = "secs.",
        title = "Time to solution by optimizer and number of vars",
    )

```julia
using Optimization
using OptimizationNLPModels
using CUTEst
using OptimizationOptimJL
using OptimizationOptimisers
using OptimizationOptimJL: LBFGS, ConjugateGradient, NelderMead, SimulatedAnnealing, ParticleSwarm
using Ipopt
using OptimizationMOI
using OptimizationMOI: MOI as MOI
using DataFrames
using Plots
using StatsPlots
using StatsBase: countmap


optimizers = [
    ("LBFGS", LBFGS()),
    ("ConjugateGradient", ConjugateGradient()),
    ("NelderMead", NelderMead()),
    ("SimulatedAnnealing", SimulatedAnnealing()),
    ("ParticleSwarm", ParticleSwarm()),
]

function get_stats(sol, optimizer_name)
    if hasfield(typeof(sol), :stats) && hasfield(typeof(sol.stats), :time)
        solve_time = sol.stats.time
    else
        solve_time = NaN
    end
    return (length(sol.u), solve_time, optimizer_name, Symbol(sol.retcode))
end

function run_benchmarks(problems, optimizers; chunk_size=1)
    problem = String[]
    n_vars = Int64[]
    secs = Float64[]
    solver = String[]
    retcode = Symbol[]
    optz = length(optimizers)
    n = length(problems)
    @info "Processing $(n) problems with $(optz) optimizers in chunks of $(chunk_size)"
    broadcast(c -> sizehint!(c, optz * n), [problem, n_vars, secs, solver, retcode])
    for chunk_start in 1:chunk_size:n
        chunk_end = min(chunk_start + chunk_size - 1, n)
        chunk_problems = problems[chunk_start:chunk_end]
        @info "Processing chunk $(div(chunk_start-1, chunk_size)+1)/$(div(n-1, chunk_size)+1): problems $(chunk_start)-$(chunk_end)"
        for (idx, prob_name) in enumerate(chunk_problems)
            current_problem = chunk_start + idx - 1
            @info "Problem $(current_problem)/$(n): $(prob_name)"
            nlp_prob = nothing
            try
                nlp_prob = CUTEstModel(prob_name)
                if nlp_prob.meta.nvar > 10000
                    @info "  Skipping $(prob_name) (too large: $(nlp_prob.meta.nvar) variables)"
                    finalize(nlp_prob)
                    continue
                end
                prob = OptimizationNLPModels.OptimizationProblem(nlp_prob, Optimization.AutoFiniteDiff())
                for (optimizer_name, optimizer) in optimizers
                    try
                        sol = solve(prob, optimizer; maxiters = 1000, maxtime = 30.0)
                        @info "âœ“ Solved $(prob_name) with $(optimizer_name) - Status: $(sol.retcode)"
                        vars, time, alg, code = get_stats(sol, optimizer_name)
                        push!(problem, prob_name)
                        push!(n_vars, vars)
                        push!(secs, time)
                        push!(solver, alg)
                        push!(retcode, code)
                    catch e
                        push!(problem, prob_name)
                        push!(n_vars, nlp_prob !== nothing ? nlp_prob.meta.nvar : -1)
                        push!(secs, NaN)
                        push!(solver, optimizer_name)
                        push!(retcode, :FAILED)
                    end
                end
            catch e
                for (optimizer_name, optimizer) in optimizers
                    push!(problem, prob_name)
                    push!(n_vars, -1)
                    push!(secs, NaN)
                    push!(solver, optimizer_name)
                    push!(retcode, :LOAD_FAILED)
                end
            finally
                if nlp_prob !== nothing
                    try
                        finalize(nlp_prob)
                    catch e
                    end
                end
            end
        end
        GC.gc()
        @info "Completed chunk, memory usage cleaned up"
    end
    return DataFrame(problem = problem, n_vars = n_vars, secs = secs, solver = solver, retcode = retcode)
end

unc_problems = collect(CUTEst.select_sif_problems(contype="unc"))
println("Number of problems: ", length(unc_problems))
println("First 5 problems: ", unc_problems[1:min(5, end)])
unc_problems = unc_problems[1:min(50, length(unc_problems))]
println("Limited to ", length(unc_problems), " problems for comprehensive testing")
unc_results =  run_benchmarks(unc_problems, optimizers)
@show unc_results
successful_codes = [:Success, :MaxIters, :MaxTime, :FirstOrderOptimal]
successful_results = filter(row -> row.retcode in successful_codes, unc_results)
total_attempts = nrow(unc_results)
successful_attempts = nrow(successful_results)
success_rate = total_attempts > 0 ? round(successful_attempts / total_attempts * 100, digits=1) : 0
println("SUCCESS RATE ANALYSIS:")
println("Total attempts: ", total_attempts)
println("Successful attempts: ", successful_attempts)
println("Success rate: ", success_rate, "%")
println("Return code distribution:")
if total_attempts > 0
    for (code, count) in sort(collect(pairs(countmap(unc_results.retcode))), by=x->x[2], rev=true)
        println("  ", code, ": ", count, " occurrences")
    end
else
    println("  No results to analyze")
end
@df unc_results scatter(:n_vars, :secs,
        group = :solver,
        xlabel = "n. variables",
        ylabel = "secs.",
        title = "Time to solution by optimizer and number of vars",
    )
```


```julia, echo = false
using SciMLBenchmarks
SciMLBenchmarks.bench_footer(WEAVE_ARGS[:folder],WEAVE_ARGS[:file])
```
