---
title: CUTEst Bounded Constrained Nonlinear Optimization Benchmarks
author: Alonso M. Cisneros
---

# Introduction

CUTEst, the Constraind and Unconstrained Testing Environment is, as the name suggests is a
collection of around 1500 problems for general nonlinear optimization used to test
optimization routines. The wrapper
[CUTEst.jl](https://github.com/JuliaSmoothOptimizers/CUTEst.jl) provides convenient access
to the problem collection, which we can leverage to test the optimizers made available by
Optimization.jl.

This benchmark uses the following packages:

```julia
using Optimization
using OptimizationNLPModels
using CUTEst
using OptimizationOptimJL
using Ipopt
using OptimizationMOI
using OptimizationMOI: MOI as MOI
# Analysis and plotting
using DataFrames
using Plots
using StatsPlots
using StatsBase: countmap
```

# Benchmarks

We will be testing the [Ipopt]() and the [LBFGS]() optimizers on these classes of
problems.

```julia
optimizers = [
    ("GradientDescent", Optimization.GradientDescent()),
    ("LBFGS", Optimization.LBFGS()),
    ("ConjugateGradient", Optimization.ConjugateGradient()),
    ("NelderMead", Optimization.NelderMead()),
    ("SimulatedAnnealing", Optimization.SimulatedAnnealing()),
    ("ParticleSwarm", Optimization.ParticleSwarm()),
]

function get_stats(sol, optimizer_name)
    if hasfield(typeof(sol), :stats) && hasfield(typeof(sol.stats), :time)
        solve_time = sol.stats.time
    else
        solve_time = NaN
    end
    return (length(sol.u), solve_time, optimizer_name, Symbol(sol.retcode))
end

function run_benchmarks(problems, optimizers; chunk_size=1)
    problem = String[]
    n_vars = Int64[]
    secs = Float64[]
    solver = String[]
    retcode = Symbol[]

    optz = length(optimizers)
    n = length(problems)

    @info "Processing $(n) problems with $(optz) optimizers in chunks of $(chunk_size)"

    broadcast(c -> sizehint!(c, optz * n), [problem, n_vars, secs, solver, retcode])

    # Process problems in chunks to manage memory
    for chunk_start in 1:chunk_size:n
        chunk_end = min(chunk_start + chunk_size - 1, n)
        chunk_problems = problems[chunk_start:chunk_end]
        
        @info "Processing chunk $(div(chunk_start-1, chunk_size)+1)/$(div(n-1, chunk_size)+1): problems $(chunk_start)-$(chunk_end)"
        
        for (idx, prob_name) in enumerate(chunk_problems)
            current_problem = chunk_start + idx - 1
            @info "Problem $(current_problem)/$(n): $(prob_name)"
            
            nlp_prob = nothing
            try
                nlp_prob = CUTEstModel(prob_name)
                
                # Generous memory limits for 100GB systems - include 5000 var problems
                if nlp_prob.meta.nvar > 10000
                    @info "  Skipping $(prob_name) (too large: $(nlp_prob.meta.nvar) variables)"
                    finalize(nlp_prob)
                    continue
                end
                
                prob = OptimizationNLPModels.OptimizationProblem(nlp_prob, Optimization.AutoForwardDiff())
                
                for (optimizer_name, optimizer) in optimizers
                    try
                        sol = solve(prob, optimizer; maxiters = 1000, maxtime = 30.0)
                        @info "✓ Solved $(prob_name) with $(optimizer_name) - Status: $(sol.retcode)"
                        vars, time, alg, code = get_stats(sol, optimizer_name)
                        push!(problem, prob_name)
                        push!(n_vars, vars)
                        push!(secs, time)
                        push!(solver, alg)
                        push!(retcode, code)
                    catch e
                        @warn "✗ Failed to solve $(prob_name) with $(optimizer_name): $(e)"
                        push!(problem, prob_name)
                        push!(n_vars, -1)
                        push!(secs, NaN)
                        push!(solver, optimizer_name)
                        push!(retcode, :FAILED)
                    end
                end
                
            catch e
                @warn "✗ Failed to load problem $(prob_name): $(e)"
                # Add failure entries for all optimizers
                for (optimizer_name, optimizer) in optimizers
                    push!(problem, prob_name)
                    push!(n_vars, -1)
                    push!(secs, NaN)
                    push!(solver, optimizer_name)
                    push!(retcode, :LOAD_FAILED)
                end
            finally
                # Aggressive cleanup to prevent memory accumulation
                if nlp_prob !== nothing
                    try
                        finalize(nlp_prob)
                    catch e
                        @warn "Failed to finalize $(prob_name): $(e)"
                    end
                end
                # Force garbage collection after each problem
                GC.gc()
            end
        end
        
        # Force garbage collection after each chunk
        GC.gc()
        @info "Completed chunk, memory usage cleaned up"
    end

    return DataFrame(problem = problem, n_vars = n_vars, secs = secs, solver = solver,
        retcode = retcode)
end
```

## Equality/Inequality constrained problems with bounded variables

Now we analyze the subset of problems with equality/inequality constraints and whose
variables are bounded. There are 666 such problems for equality constraints and 244 for inequality constraints.

The following figure shows the results of the same benchmarks previously described for the
problems on this section.

```julia
@info "before"
eq_bou_problems = CUTEst.select_sif_problems(min_con=1, only_equ_con=true, only_free_var=false)
@info "after1 - testing $(length(eq_bou_problems)) equality-constrained problems"

# Limit to first 50 problems for 100GB memory systems
eq_bou_problems = eq_bou_problems[1:min(50, length(eq_bou_problems))]
@info "Limited to $(length(eq_bou_problems)) problems for comprehensive testing"

# Analysis
eq_bou_results =  run_benchmarks(eq_bou_problems, optimizers)

# Calculate and display success rates
successful_codes = [:Success, :MaxIters, :MaxTime, :FirstOrderOptimal]
successful_results = filter(row -> row.retcode in successful_codes, eq_bou_results)
total_attempts = nrow(eq_bou_results)
successful_attempts = nrow(successful_results)
success_rate = total_attempts > 0 ? round(successful_attempts / total_attempts * 100, digits=1) : 0

@info "SUCCESS RATE ANALYSIS:"
@info "Total attempts: $(total_attempts)"
@info "Successful attempts: $(successful_attempts)"
@info "Success rate: $(success_rate)%"

@info "after2"

@df eq_bou_results scatter(:n_vars, :secs,
        group = :solver,
        xlabel = "n. variables",
        ylabel = "secs.",
        title = "Time to solution by optimizer and number of vars",
    )
@info "after3"
```

Next, we examine the same relationship for inequality-constrained problems.

```julia
@info "after4"
neq_bou_problems = CUTEst.select_sif_problems(min_con=1, only_ineq_con=true, only_free_var=false)
@info "after5 - testing $(length(neq_bou_problems)) inequality-constrained problems"

# Limit to first 50 problems for 100GB memory systems
neq_bou_problems = neq_bou_problems[1:min(50, length(neq_bou_problems))]
@info "Limited to $(length(neq_bou_problems)) problems for comprehensive testing"

# Analysis
neq_bou_results =  run_benchmarks(neq_bou_problems, optimizers)

# Calculate and display success rates  
successful_codes = [:Success, :MaxIters, :MaxTime, :FirstOrderOptimal]
successful_results = filter(row -> row.retcode in successful_codes, neq_bou_results)
total_attempts = nrow(neq_bou_results)
successful_attempts = nrow(successful_results)
success_rate = total_attempts > 0 ? round(successful_attempts / total_attempts * 100, digits=1) : 0

@info "INEQUALITY CONSTRAINED SUCCESS RATE: $(success_rate)% ($(successful_attempts)/$(total_attempts))"

@info "after6"

@df neq_bou_results scatter(:n_vars, :secs,
        group = :solver,
        xlabel = "n. variables",
        ylabel = "secs.",
        title = "Time to solution by optimizer and number of vars",
    )
```

```julia, echo = false
using SciMLBenchmarks
SciMLBenchmarks.bench_footer(WEAVE_ARGS[:folder],WEAVE_ARGS[:file])
```
